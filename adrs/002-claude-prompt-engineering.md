# ADR 002: Prompt Engineering for Incident Summarization

## Status

Accepted

## Context

For our MVP Slack incident summarization bot, we need to effectively extract structured information from unstructured Slack conversations. The quality of the summaries generated by our system will depend heavily on how well we can instruct LLM to identify and extract relevant information from these conversations.

Incident investigation threads in Slack typically contain:
- Technical discussions about symptoms and potential causes
- Diagnostic steps and their results
- Resolution actions and verification
- Timeline information scattered throughout the conversation
- Images such as screenshots, error messages, and monitoring graphs
- Tangential discussions and noise

We need a prompt engineering approach that enables LLM to:
1. Distinguish between relevant and irrelevant information
2. Correctly identify the incident cause, impact, resolution steps, and timeline
3. Interpret and incorporate information from images shared in the conversation
4. Present this information in a consistent, management-friendly format
5. Handle various conversation patterns and edge cases

## Decision

We will implement a structured prompt engineering approach for LLM that includes:

1. **System Instructions**: Clear definition of LLM's role and task
2. **Context Setting**: Information about the nature of Slack incident conversations
3. **Specific Extraction Guidelines**: Detailed instructions on what information to extract
4. **Image Analysis Instructions**: Guidelines for interpreting and incorporating visual information
5. **Output Format Template**: Consistent structure for the generated summaries
6. **Edge Case Handling**: Instructions for dealing with incomplete or ambiguous information

### Prompt Structure

The prompt will follow this structure:

```
[System Instructions]
You are an incident analysis assistant. Your task is to analyze a Slack conversation about an incident and extract key information to create a concise summary for management.

[Context]
The following is a Slack conversation from an incident investigation thread. The conversation involves engineers discussing and resolving a technical incident related to our microservices running on AWS. The conversation may include images such as screenshots of error messages, monitoring dashboards, or logs.

[Task Description]
Analyze the conversation and extract the following information:
1. Incident cause: What triggered or caused the incident (e.g., deployment error, infrastructure issue, external dependency)
2. Impact: What systems or users were affected and how severely (e.g., service downtime, degraded performance, data loss)
3. Resolution steps: What actions were taken to resolve the incident (e.g., rollback, configuration change, scaling)
4. Timeline: When the incident started, key events during investigation, and when it was resolved

[Image Analysis]
For any images in the conversation:
- Describe what the image shows (e.g., error message, graph, screenshot)
- Extract relevant information from the image (e.g., error codes, metrics, timestamps)
- Incorporate this information into your analysis of cause, impact, resolution, or timeline
- If an image appears to contain critical information but you cannot fully interpret it, note this in your summary

[Special Instructions]
- If certain information is not explicitly stated, indicate this clearly rather than making assumptions
- Maintain technical accuracy while making the summary accessible to non-technical stakeholders
- If the conversation contains conflicting theories or information, note the final consensus or indicate that the cause was not definitively determined
- If the conversation appears to discuss multiple incidents, focus on the primary incident being investigated

[Output Format]
Provide your analysis in the following format:

## Incident Summary

**Cause:**
[1-2 sentences describing the root cause]

**Impact:**
[1-2 sentences describing who/what was affected and how]

**Resolution:**
- [Bullet point of action taken]
- [Bullet point of action taken]
- [Bullet point of action taken]

**Timeline:**
- [Time] Incident began
- [Time] [Key event]
- [Time] [Key event]
- [Time] Incident resolved

**Key Visual Evidence:**
- [Brief description of significant image and what it revealed]
- [Brief description of significant image and what it revealed]

[Conversation]
{The actual Slack conversation will be inserted here}
```

### Sample Expected Output

For a conversation about a database connection issue, the expected output would be:

```
## Incident Summary

**Cause:**
Connection pool exhaustion in svc-auth database due to a query in the recent deployment that wasn't properly closing connections.

**Impact:**
The authentication service experienced high latency (>2s) affecting approximately 15% of login attempts between 14:30-15:45 UTC.

**Resolution:**
- Identified the problematic query in the user-profile endpoint
- Deployed hotfix to properly close database connections
- Restarted the user-service to clear existing connection pool
- Verified authentication service response times returned to normal (<200ms)

**Timeline:**
- 14:30 UTC: Monitoring alert triggered for high authentication latency
- 14:35 UTC: Investigation began, identified database connection pool as bottleneck
- 15:10 UTC: Root cause identified as connection leak in new deployment
- 15:30 UTC: Hotfix deployed
- 15:45 UTC: Service fully recovered

**Key Visual Evidence:**
- New Relic dashboard screenshot showing spike in database connections at 14:30 UTC
- Log screenshot showing repeated "connection timeout" errors in the user-service
```

## Implementation Approach

1. **Initial Prompt Development**
   - Create base prompt template following the structure above
   - Develop variations for different incident types (service outage, performance degradation, etc.)
   - Test with sample conversations from past incidents

2. **Image Handling Strategy**
   - Leverage LLM's vision capabilities to analyze screenshots and graphs
   - Develop specific prompts for common image types (error logs, metrics dashboards, architecture diagrams)
   - Create guidelines for extracting quantitative data from graphs and charts

3. **Evaluation Framework**
   - Define metrics for evaluating summary quality:
     - Accuracy: Correctness of extracted information
     - Completeness: Inclusion of all relevant details
     - Visual interpretation: Correct analysis of images
     - Clarity: Readability and understandability for management
     - Conciseness: Appropriate length and focus
   - Create evaluation rubric with scoring guidelines

4. **Iteration Process**
   - Implement feedback loop with on-call engineers
   - Collect examples of good and poor summaries
   - Regularly update prompts based on performance data
   - Version control all prompt changes

5. **Edge Case Handling**
   - Develop specific prompt additions for common challenges:
     - Incidents with unclear resolution
     - Multiple overlapping issues
     - Highly technical discussions
     - Incomplete information
     - Low-quality or ambiguous images

## Consequences

### Advantages

1. **Structured Information**: Consistent format makes summaries easy to read and compare
2. **Visual Context Integration**: Incorporation of image data provides richer understanding
3. **Adaptability**: Prompt-based approach allows for quick iterations without code changes
4. **Quality Control**: Explicit instructions reduce hallucinations and improve accuracy
5. **Knowledge Transfer**: Well-structured summaries build institutional knowledge about incidents

### Limitations

1. **Conversation Variability**: Slack conversations can vary widely in structure and content
2. **Context Length**: Very long conversations may exceed LLM's context window
3. **Image Interpretation Challenges**: Complex visualizations may be difficult to fully interpret
4. **Technical Complexity**: Some incidents may involve technical details that are difficult to summarize concisely

### Future Considerations

1. **Prompt Specialization**: Develop domain-specific prompts for different types of services
2. **Feedback Integration**: Add mechanism for engineers to provide feedback on summary quality
3. **Advanced Image Analysis**: Improve handling of complex visualizations and charts
4. **Historical Context**: Include information from past similar incidents

## References

- [Anthropic Claude Documentation](https://docs.anthropic.com/claude/docs)
- [AWS Bedrock Claude Integration](https://aws.amazon.com/bedrock/claude/)
- [Claude Vision Capabilities](https://www.anthropic.com/index/claude-3-vision)
- [Prompt Engineering Best Practices](https://www.anthropic.com/index/prompting-guide)